{
  "content": [
    {
      "element": "h1",
      "text": "Hyper-parameter Tuning"
    },
    {
      "element": "p",
      "description": "In machine learning, hyperparameter optimization or tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm. A hyperparameter is a parameter whose value is used to control the learning process"
    },
    {
      "element": "p",
      "description": "Hyperparameter tuning allows data scientists to tweak model performance for optimal results. This process is an essential part of machine learning, and choosing appropriate hyperparameter values is crucial for success. For example, assume you're using the learning rate of the model as a hyperparameter."
    },
    {
      "element": "h2",
      "description": "Grid Search"
    },
    {
      "element": "p",
      "description": "Grid Search uses a different combination of all the specified hyperparameters and their values and calculates the performance for each combination and selects the best value for the hyperparameters. This makes the processing time-consuming and expensive based on the number of hyperparameters involved."
    },
    {
      "element": "img",
      "description": "/images/grid-search.png"
    },
    {
      "element": "img",
      "description": "/images/grid-pred.png"
    },
    {
      "element": "h2",
      "description": "Random Search"
    },
    {
      "element": "p",
      "description": "Random searches are very similar to grid searches. However, instead of testing every combination of hyperparameters, random searches only test a certain number of combinations that are selected randomly."
    },
    {
      "element": "img",
      "description": "/images/random-search.png"
    },
    {
      "element": "img",
      "description": "/images/random-pred.png"
    },
    {
      "element": "h2",
      "description": "Bayesian Search"
    },
    {
      "element": "p",
      "description": "Hyperparameter tuning by means of Bayesian reasoning, or Bayesian Optimisation, can bring down the time spent to get to the optimal set of parameters â€” and bring better generalisation performance on the test set."
    },
    {
      "element": "img",
      "description": "/images/bayesian1.png"
    },
    {
      "element": "img",
      "description": "/images/bayesian1.png"
    },
    {
      "element": "h2",
      "description": "Hyperband"
    },
    {
      "element": "p",
      "description": "The Hyperband tuning algorithm uses adaptive resource allocation and early-stopping to quickly converge on a high-performing model."
    },
    {
      "element": "img",
      "description": "/images/hyperband.png"
    }
  ]
}